{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JUzgK08aqAb_",
        "azvbdHGNwq7s",
        "D-JSchtmq3Ec",
        "h7tT1Gl4q8ve",
        "rzTOeYZ-wwgI",
        "VHqTsfcFsBvu",
        "PIiF8RxOw1iK",
        "D4TNUQlbtWQP",
        "TLq_Gmvm3zPg",
        "_KjOO6cH34OL",
        "Pj5i1vIT35az",
        "qFjWlkdCvN6u",
        "V_V5ylyavaoq",
        "q2D15TMUvarj",
        "Mq8-duCwva1m",
        "HvxlFF-6vbIf",
        "3sy53eq7vbSr",
        "uLPGrscwxMtK",
        "qQ9q3CYkxO4y",
        "KWvcCIBkxPES",
        "2uASiwhC6Flf",
        "F714sWh36ILx",
        "29MLDOU96Mn4",
        "aJsY5dci6QUx",
        "g11rb3JxRfU2",
        "VT9JENdWRjvH",
        "p5r7_OwrvWuT"
      ],
      "authorship_tag": "ABX9TyOWW7GAyPNs5d932sZO3hxG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "4e4qYqYdeyVF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7goPmYm7clD"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def union_files(file1, file2, output_file):\n",
        "    # Read data from file 1\n",
        "    df1 = pd.read_excel(file1)\n",
        "\n",
        "    # Read data from file 2\n",
        "    df2 = pd.read_excel(file2)\n",
        "\n",
        "    # Concatenate the two dataframes\n",
        "    union_df = pd.concat([df1, df2])\n",
        "\n",
        "    # Write union data to the output file\n",
        "    union_df.to_excel(output_file, index=False)\n",
        "\n",
        "    print(f\"Union data has been written to {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "file1 = 'NegData.xlsx'\n",
        "file2 = 'PosData.xlsx'\n",
        "output_file = 'BData.xlsx'\n",
        "\n",
        "union_files(file1, file2, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_-k7EPR8ILB",
        "outputId": "f2c11a79-7be1-4e64-922c-8c90e659e486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Union data has been written to BData.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the file name\n",
        "filename = \"BData.xlsx\"\n",
        "\n",
        "# Read the Excel file using pandas\n",
        "data = pd.read_excel(filename)\n",
        "\n",
        "# Print the data\n",
        "print(data.head(-10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-qp-kzu8gSu",
        "outputId": "5fac2aa2-4188-4fe7-8416-57223b038b11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              tweet_text     label\n",
            "0      Here at home. Neighbors pick on my family and ...  negative\n",
            "1      Being bullied at school: High-achieving boys u...  negative\n",
            "2      There was a girl in my class in 6th grade who ...  negative\n",
            "3      Heâ€™s probably a white gay kid from some subu...  negative\n",
            "4      You are pushed ti resorting. Treating thr bull...  negative\n",
            "...                                                  ...       ...\n",
            "15785  Yeah, that should put an end to the bullying -...  positive\n",
            "15786                 Bullying NEEDS stop! #StopBullying  positive\n",
            "15787  This is the best point I've seen made about #t...  positive\n",
            "15788  NO KAT IS STILL IN THE COMPETITION GET OUT GET...  positive\n",
            "15789  @dllvllHllvllb @hyperion5182 @PolitiBunny @The...  positive\n",
            "\n",
            "[15790 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "Baj-VY8i8opX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df256bb-586a-43b8-af52-36483b46ee71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Excel file into a DataFrame\n",
        "data = pd.read_excel(\"BData.xlsx\")\n",
        "\n",
        "# Function to preprocess a single tweet\n",
        "def preprocess_tweet(tweet):\n",
        "    # Convert to lowercase\n",
        "\n",
        "    if isinstance(tweet, float):\n",
        "        tweet = str(tweet)  # Convert float to string\n",
        "\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    tweet = tweet.replace('â', '')\n",
        "\n",
        "    # Remove URLs, usernames, hashtags\n",
        "    tweet = re.sub(r\"http\\S+|www\\S+|@\\S+|#\\S+\", \"\", tweet)\n",
        "\n",
        "    # Remove non-alphanumeric characters and punctuation\n",
        "    tweet = re.sub(r\"[^\\w\\s]\", \"\", tweet)\n",
        "\n",
        "    # Tokenize the tweet into words\n",
        "    tokens = word_tokenize(tweet)\n",
        "\n",
        "    # Remove specific words\n",
        "    tokens = [token for token in tokens if token not in ['yang', 'ni','tak','dan','di','nak','tu','yg','ke','dah','ada','dia','untuk','aku','kena','pun',\n",
        "                                                         'ini','buat','la','semua','lagi','ðÿ','boleh','dengan','kalau','je','kita','dalam','bagi','tapi',\n",
        "                                                         'kat','sebab','lah','kepada','dari','masa','apa','bukan','baru','mana','tolong','kau','bantu','banjir',\n",
        "                                                         'macam','ngan','â']]\n",
        "\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Lemmatize the tokens\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "\n",
        "    # Join the tokens back into a string\n",
        "    preprocessed_tweet = \" \".join(lemmatized_tokens)\n",
        "\n",
        "    return preprocessed_tweet\n",
        "\n",
        "# Apply the preprocessing function to the tweet text column\n",
        "data['cleaned_tweet'] = data['tweet_text'].apply(preprocess_tweet)\n",
        "\n",
        "# Print the cleaned data\n",
        "print(data[['tweet_text', 'cleaned_tweet']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGwpR0KXcdfk",
        "outputId": "7b0c4625-18fd-47b8-a051-9f4c3d43c57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          tweet_text  \\\n",
            "0  Here at home. Neighbors pick on my family and ...   \n",
            "1  Being bullied at school: High-achieving boys u...   \n",
            "2  There was a girl in my class in 6th grade who ...   \n",
            "3  Heâ€™s probably a white gay kid from some subu...   \n",
            "4  You are pushed ti resorting. Treating thr bull...   \n",
            "\n",
            "                                       cleaned_tweet  \n",
            "0  home neighbor pick family mind son autistic fe...  \n",
            "1  bullied school highachieving boy use strategy ...  \n",
            "2  girl class 6th grade little autistic parent th...  \n",
            "3  he probably white gay kid suburb dont want sho...  \n",
            "4  pushed ti resorting treating thr bully percent...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aZJLJbaLczWT",
        "outputId": "31a38d8d-2685-4922-a582-9b5f38ab8696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          tweet_text     label  \\\n",
              "0  Here at home. Neighbors pick on my family and ...  negative   \n",
              "1  Being bullied at school: High-achieving boys u...  negative   \n",
              "2  There was a girl in my class in 6th grade who ...  negative   \n",
              "3  Heâ€™s probably a white gay kid from some subu...  negative   \n",
              "4  You are pushed ti resorting. Treating thr bull...  negative   \n",
              "\n",
              "                                       cleaned_tweet  \n",
              "0  home neighbor pick family mind son autistic fe...  \n",
              "1  bullied school highachieving boy use strategy ...  \n",
              "2  girl class 6th grade little autistic parent th...  \n",
              "3  he probably white gay kid suburb dont want sho...  \n",
              "4  pushed ti resorting treating thr bully percent...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-0a60135d-6405-4767-b5cb-7c12ab3d897e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Here at home. Neighbors pick on my family and ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>home neighbor pick family mind son autistic fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Being bullied at school: High-achieving boys u...</td>\n",
              "      <td>negative</td>\n",
              "      <td>bullied school highachieving boy use strategy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There was a girl in my class in 6th grade who ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>girl class 6th grade little autistic parent th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Heâ€™s probably a white gay kid from some subu...</td>\n",
              "      <td>negative</td>\n",
              "      <td>he probably white gay kid suburb dont want sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You are pushed ti resorting. Treating thr bull...</td>\n",
              "      <td>negative</td>\n",
              "      <td>pushed ti resorting treating thr bully percent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a60135d-6405-4767-b5cb-7c12ab3d897e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-108bcccf-f7d6-47fc-acd7-78f748e91c74\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-108bcccf-f7d6-47fc-acd7-78f748e91c74')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-108bcccf-f7d6-47fc-acd7-78f748e91c74 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a60135d-6405-4767-b5cb-7c12ab3d897e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a60135d-6405-4767-b5cb-7c12ab3d897e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop([\"tweet_text\"], axis=1, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s6yn05veem81",
        "outputId": "e93f699f-e1a9-4d24-977a-6ebc8a1fd2d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                      cleaned_tweet\n",
              "0  negative  home neighbor pick family mind son autistic fe...\n",
              "1  negative  bullied school highachieving boy use strategy ...\n",
              "2  negative  girl class 6th grade little autistic parent th...\n",
              "3  negative  he probably white gay kid suburb dont want sho...\n",
              "4  negative  pushed ti resorting treating thr bully percent..."
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-05868f19-3302-4cea-bd7e-93ad1d195c1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>home neighbor pick family mind son autistic fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>bullied school highachieving boy use strategy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>girl class 6th grade little autistic parent th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>he probably white gay kid suburb dont want sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>pushed ti resorting treating thr bully percent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05868f19-3302-4cea-bd7e-93ad1d195c1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-c7791ebd-039a-4282-b93e-1f9a2a8b705a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7791ebd-039a-4282-b93e-1f9a2a8b705a')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-c7791ebd-039a-4282-b93e-1f9a2a8b705a button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05868f19-3302-4cea-bd7e-93ad1d195c1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05868f19-3302-4cea-bd7e-93ad1d195c1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_tweet'] = data['cleaned_tweet'].astype(str)\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "data['cleaned_tweet'] = data['cleaned_tweet'].apply(lambda x: tokenizer.tokenize(x))\n",
        "print(data['cleaned_tweet'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHrzRzNujm2x",
        "outputId": "29c8ca96-1706-453a-87fd-0baf0e057171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        [home, neighbor, pick, family, mind, son, auti...\n",
            "1        [bullied, school, highachieving, boy, use, str...\n",
            "2        [girl, class, 6th, grade, little, autistic, pa...\n",
            "3        [he, probably, white, gay, kid, suburb, dont, ...\n",
            "4        [pushed, ti, resorting, treating, thr, bully, ...\n",
            "                               ...                        \n",
            "15795    [time, ready, 3, year, old, whorl, wind, come,...\n",
            "15796                              [everyone, look, tired]\n",
            "15797                                 [follow, back, dude]\n",
            "15798    [rt, fought, hard, entire, comp, amp, wouldnt,...\n",
            "15799                                           [go, manu]\n",
            "Name: cleaned_tweet, Length: 15800, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Create a list to store all the words\n",
        "all_words = []\n",
        "\n",
        "# Iterate over each list of tokenized words in the 'cleaned_tweet' column\n",
        "for tokens in data['cleaned_tweet']:\n",
        "    all_words.extend(tokens)\n",
        "\n",
        "# Count the frequency of each word\n",
        "word_counts = Counter(all_words)\n",
        "\n",
        "# Get the most common words and their frequencies\n",
        "top_words = word_counts.most_common(15)\n",
        "\n",
        "# Print the top words\n",
        "for word, count in top_words:\n",
        "    print(f\"{word}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF53UjUrj_t7",
        "outputId": "c91337a3-0bbc-42c6-ce86-68fdffb2d5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "school: 2025\n",
            "like: 1554\n",
            "rt: 1471\n",
            "u: 1337\n",
            "bully: 1299\n",
            "fuck: 1259\n",
            "im: 1218\n",
            "people: 1190\n",
            "girl: 1173\n",
            "dont: 1153\n",
            "muslim: 1131\n",
            "nigger: 1088\n",
            "joke: 1044\n",
            "dumb: 1034\n",
            "high: 1019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of top words to be labeled as 1\n",
        "top_words = ['school','like', 'rt', 'u', 'bully','fuck','im','people','girl','dont','muslim','nigger','joke','dumb']\n",
        "\n",
        "# Function to assign labels\n",
        "def assign_label(tokens):\n",
        "    # Check if any of the top words is present in the tokens\n",
        "    if any(word in tokens for word in top_words):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Apply the label assignment function to the tokenized tweets\n",
        "data['label'] = data['cleaned_tweet'].apply(assign_label)\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(data[['cleaned_tweet', 'label']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBkCmaaakCx2",
        "outputId": "92d98e73-441b-4c93-9599-faeb01635cff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           cleaned_tweet  label\n",
            "0      [home, neighbor, pick, family, mind, son, auti...      1\n",
            "1      [bullied, school, highachieving, boy, use, str...      1\n",
            "2      [girl, class, 6th, grade, little, autistic, pa...      1\n",
            "3      [he, probably, white, gay, kid, suburb, dont, ...      1\n",
            "4      [pushed, ti, resorting, treating, thr, bully, ...      1\n",
            "...                                                  ...    ...\n",
            "15795  [time, ready, 3, year, old, whorl, wind, come,...      0\n",
            "15796                            [everyone, look, tired]      0\n",
            "15797                               [follow, back, dude]      0\n",
            "15798  [rt, fought, hard, entire, comp, amp, wouldnt,...      1\n",
            "15799                                         [go, manu]      0\n",
            "\n",
            "[15800 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of tweets for each label\n",
        "label_counts = data['label'].value_counts()\n",
        "\n",
        "# Print the counts\n",
        "print(label_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h_yPgKjlT_l",
        "outputId": "05615cb8-9e97-40cc-bb63-f4d45e8d557f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    8697\n",
            "0    7103\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "H-uCx1tOlXsL",
        "outputId": "c5e421df-a8bb-4de1-9b9c-8e3dddf43df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                      cleaned_tweet\n",
              "0          1  [home, neighbor, pick, family, mind, son, auti...\n",
              "1          1  [bullied, school, highachieving, boy, use, str...\n",
              "2          1  [girl, class, 6th, grade, little, autistic, pa...\n",
              "3          1  [he, probably, white, gay, kid, suburb, dont, ...\n",
              "4          1  [pushed, ti, resorting, treating, thr, bully, ...\n",
              "...      ...                                                ...\n",
              "15795      0  [time, ready, 3, year, old, whorl, wind, come,...\n",
              "15796      0                            [everyone, look, tired]\n",
              "15797      0                               [follow, back, dude]\n",
              "15798      1  [rt, fought, hard, entire, comp, amp, wouldnt,...\n",
              "15799      0                                         [go, manu]\n",
              "\n",
              "[15800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-c2b26e53-6d53-4586-8407-e0f54a0f3a70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[home, neighbor, pick, family, mind, son, auti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[bullied, school, highachieving, boy, use, str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[girl, class, 6th, grade, little, autistic, pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[he, probably, white, gay, kid, suburb, dont, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>[pushed, ti, resorting, treating, thr, bully, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15795</th>\n",
              "      <td>0</td>\n",
              "      <td>[time, ready, 3, year, old, whorl, wind, come,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15796</th>\n",
              "      <td>0</td>\n",
              "      <td>[everyone, look, tired]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15797</th>\n",
              "      <td>0</td>\n",
              "      <td>[follow, back, dude]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15798</th>\n",
              "      <td>1</td>\n",
              "      <td>[rt, fought, hard, entire, comp, amp, wouldnt,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15799</th>\n",
              "      <td>0</td>\n",
              "      <td>[go, manu]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2b26e53-6d53-4586-8407-e0f54a0f3a70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-bbcbe100-53b8-4a31-9099-b9011b62a7f1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbcbe100-53b8-4a31-9099-b9011b62a7f1')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-bbcbe100-53b8-4a31-9099-b9011b62a7f1 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2b26e53-6d53-4586-8407-e0f54a0f3a70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2b26e53-6d53-4586-8407-e0f54a0f3a70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logic Regression\n"
      ],
      "metadata": {
        "id": "Hv4Ah3AflkvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BoW"
      ],
      "metadata": {
        "id": "BS2rigg2xCXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "lJ0jdkgKm9QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR + BoW + 70/30\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert the lists of strings to a single string\n",
        "X_train = [\" \".join(tokens) for tokens in X_train]\n",
        "X_test = [\" \".join(tokens) for tokens in X_test]\n",
        "\n",
        "# Create a pipeline that combines CountVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "LR_bow_1 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJc9IDhXlsTQ",
        "outputId": "614eff8b-6de7-4a36-8c3a-fbb518654788"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9824894514767932\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      2131\n",
            "           1       0.99      0.97      0.98      2609\n",
            "\n",
            "    accuracy                           0.98      4740\n",
            "   macro avg       0.98      0.98      0.98      4740\n",
            "weighted avg       0.98      0.98      0.98      4740\n",
            "\n",
            "Accuracy: 0.9824894514767932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "mqzFgvOfnK5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR + BoW + 80/20\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the lists of strings to a single string\n",
        "X_train = [\" \".join(tokens) for tokens in X_train]\n",
        "X_test = [\" \".join(tokens) for tokens in X_test]\n",
        "\n",
        "# Create a pipeline that combines CountVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "LR_bow_2 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2_axGVVnREA",
        "outputId": "bb9019bc-0971-4f95-f2e0-389e1f647141"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9819620253164557\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98      1445\n",
            "           1       0.99      0.97      0.98      1715\n",
            "\n",
            "    accuracy                           0.98      3160\n",
            "   macro avg       0.98      0.98      0.98      3160\n",
            "weighted avg       0.98      0.98      0.98      3160\n",
            "\n",
            "Accuracy: 0.9819620253164557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "roWYtRFlwJah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR + BoW + 80/20\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert the lists of strings to a single string\n",
        "X_train = [\" \".join(tokens) for tokens in X_train]\n",
        "X_test = [\" \".join(tokens) for tokens in X_test]\n",
        "\n",
        "# Create a pipeline that combines CountVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', CountVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "LR_bow_3 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMxM5Dq06ruD",
        "outputId": "316a8f66-c702-4a97-c3b4-f33de5228856"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9835443037974684\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       719\n",
            "           1       1.00      0.97      0.98       861\n",
            "\n",
            "    accuracy                           0.98      1580\n",
            "   macro avg       0.98      0.98      0.98      1580\n",
            "weighted avg       0.98      0.98      0.98      1580\n",
            "\n",
            "Accuracy: 0.9835443037974684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "9mTwQIrfoBBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "uKDHAsxwwbBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_tfidf_1 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhw75KczoW71",
        "outputId": "abe15123-b473-47d1-f774-526376df59d7"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9736286919831224\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      2131\n",
            "           1       0.99      0.96      0.98      2609\n",
            "\n",
            "    accuracy                           0.97      4740\n",
            "   macro avg       0.97      0.97      0.97      4740\n",
            "weighted avg       0.97      0.97      0.97      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "B5jFBE9JodXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_tfidf_1 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i8HhD_cohJy",
        "outputId": "36f172c8-ec7d-4cf8-f8d0-7d2facf26071"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9740506329113924\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1445\n",
            "           1       0.99      0.96      0.98      1715\n",
            "\n",
            "    accuracy                           0.97      3160\n",
            "   macro avg       0.97      0.98      0.97      3160\n",
            "weighted avg       0.97      0.97      0.97      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "y1vafgjEwjl8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_tfidf_1 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPq_1LcGydvi",
        "outputId": "bf62a92f-c896-4ef1-9aa7-da364f65ccc8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9734177215189873\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       719\n",
            "           1       0.99      0.96      0.98       861\n",
            "\n",
            "    accuracy                           0.97      1580\n",
            "   macro avg       0.97      0.97      0.97      1580\n",
            "weighted avg       0.97      0.97      0.97      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "3G3EUhQ81wnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "rB4jHNe013si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train and X_test to lists\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "\n",
        "# Train Word2Vec embeddings on the training data\n",
        "embedding_dim = 100\n",
        "model = Word2Vec(sentences=X_train_list, vector_size=embedding_dim, window=5, min_count=1)\n",
        "\n",
        "# Convert tweets to averaged Word2Vec vectors\n",
        "X_train_w2v = np.array([np.mean([model.wv[word] for word in tweet if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
        "                        for tweet in X_train_list])\n",
        "X_test_w2v = np.array([np.mean([model.wv[word] for word in tweet if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
        "                       for tweet in X_test_list])\n",
        "\n",
        "# Create a pipeline that combines Word2Vec and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test_w2v)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_word2vec_1 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1J2BZlno2Dyx",
        "outputId": "a54cdcd0-0ced-490f-bcc5-a668b5ac9cde"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7725738396624473\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.69      0.73      2131\n",
            "           1       0.77      0.84      0.80      2609\n",
            "\n",
            "    accuracy                           0.77      4740\n",
            "   macro avg       0.77      0.76      0.77      4740\n",
            "weighted avg       0.77      0.77      0.77      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/30] ---"
      ],
      "metadata": {
        "id": "cRN6FgA41_vD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.8, random_state=42)\n",
        "\n",
        "# Convert X_train and X_test to lists\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "\n",
        "# Train Word2Vec embeddings on the training data\n",
        "embedding_dim = 100\n",
        "model = Word2Vec(sentences=X_train_list, vector_size=embedding_dim, window=5, min_count=1)\n",
        "\n",
        "# Convert tweets to averaged Word2Vec vectors\n",
        "X_train_w2v = np.array([np.mean([model.wv[word] for word in tweet if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
        "                        for tweet in X_train_list])\n",
        "X_test_w2v = np.array([np.mean([model.wv[word] for word in tweet if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
        "                       for tweet in X_test_list])\n",
        "\n",
        "# Create a pipeline that combines Word2Vec and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test_w2v)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_word2vec_2 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC2oRmwY2EJ_",
        "outputId": "23ac33d0-6ead-47c3-d7cc-d23a38c74c7a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7734177215189874\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.61      0.71      5685\n",
            "           1       0.74      0.91      0.81      6955\n",
            "\n",
            "    accuracy                           0.77     12640\n",
            "   macro avg       0.79      0.76      0.76     12640\n",
            "weighted avg       0.79      0.77      0.77     12640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "ZpH7HXYs1_eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train and X_test to lists\n",
        "X_train_list = X_train.tolist()\n",
        "X_test_list = X_test.tolist()\n",
        "\n",
        "# Train Word2Vec embeddings on the training data\n",
        "embedding_dim = 100\n",
        "model = Word2Vec(sentences=X_train_list, vector_size=embedding_dim, window=5, min_count=1)\n",
        "\n",
        "# Convert tweets to averaged Word2Vec vectors\n",
        "X_train_w2v = np.array([np.mean([model.wv[word] for word in tweet if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
        "                        for tweet in X_train_list])\n",
        "X_test_w2v = np.array([np.mean([model.wv[word] for word in tweet if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
        "                       for tweet in X_test_list])\n",
        "\n",
        "# Create a pipeline that combines Word2Vec and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train_w2v, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test_w2v)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_word2vec_3 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ELf-PwZ2EpQ",
        "outputId": "819f9206-ce83-400d-ce38-910b9cbe2126"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7670886075949367\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.69      0.73       719\n",
            "           1       0.76      0.84      0.80       861\n",
            "\n",
            "    accuracy                           0.77      1580\n",
            "   macro avg       0.77      0.76      0.76      1580\n",
            "weighted avg       0.77      0.77      0.77      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machine"
      ],
      "metadata": {
        "id": "JUzgK08aqAb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BoW"
      ],
      "metadata": {
        "id": "azvbdHGNwq7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "D-JSchtmq3Ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM + BoW + 70/30\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert the lists of strings to a single string\n",
        "X_train_text = [\" \".join(tokens) for tokens in X_train]\n",
        "X_test_text = [\" \".join(tokens) for tokens in X_test]\n",
        "\n",
        "# Initialize the CountVectorizer with adjusted parameters\n",
        "vectorizer = CountVectorizer(min_df=2)  # Adjust the min_df parameter as needed\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Fit the SVM model on the training data\n",
        "svm_model.fit(X_train_bow, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = svm_model.predict(X_test_bow)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbGPNxlEqyR0",
        "outputId": "b381d029-ec8a-4879-a539-4cb01503fb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9791139240506329\n",
            "Confusion Matrix:\n",
            "[[2089   42]\n",
            " [  57 2552]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      2131\n",
            "           1       0.98      0.98      0.98      2609\n",
            "\n",
            "    accuracy                           0.98      4740\n",
            "   macro avg       0.98      0.98      0.98      4740\n",
            "weighted avg       0.98      0.98      0.98      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "h7tT1Gl4q8ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM + BoW + 80/20\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the lists of strings to a single string\n",
        "X_train_text = [\" \".join(tokens) for tokens in X_train]\n",
        "X_test_text = [\" \".join(tokens) for tokens in X_test]\n",
        "\n",
        "# Initialize the CountVectorizer with adjusted parameters\n",
        "vectorizer = CountVectorizer(min_df=2)  # Adjust the min_df parameter as needed\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Fit the SVM model on the training data\n",
        "svm_model.fit(X_train_bow, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = svm_model.predict(X_test_bow)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpLGgJTurCs3",
        "outputId": "833c7908-43c6-410f-b3b3-4e17ef0fe40c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9787974683544304\n",
            "Confusion Matrix:\n",
            "[[1413   32]\n",
            " [  35 1680]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1445\n",
            "           1       0.98      0.98      0.98      1715\n",
            "\n",
            "    accuracy                           0.98      3160\n",
            "   macro avg       0.98      0.98      0.98      3160\n",
            "weighted avg       0.98      0.98      0.98      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "rzTOeYZ-wwgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM + BoW + 80/20\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert the lists of strings to a single string\n",
        "X_train_text = [\" \".join(tokens) for tokens in X_train]\n",
        "X_test_text = [\" \".join(tokens) for tokens in X_test]\n",
        "\n",
        "# Initialize the CountVectorizer with adjusted parameters\n",
        "vectorizer = CountVectorizer(min_df=2)  # Adjust the min_df parameter as needed\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Fit the SVM model on the training data\n",
        "svm_model.fit(X_train_bow, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = svm_model.predict(X_test_bow)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJPiMFZ7yOep",
        "outputId": "05b36938-6115-4626-9aab-996172c0553d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9772151898734177\n",
            "Confusion Matrix:\n",
            "[[702  17]\n",
            " [ 19 842]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       719\n",
            "           1       0.98      0.98      0.98       861\n",
            "\n",
            "    accuracy                           0.98      1580\n",
            "   macro avg       0.98      0.98      0.98      1580\n",
            "weighted avg       0.98      0.98      0.98      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "VHqTsfcFsBvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "PIiF8RxOw1iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF8bnNVvrkeZ",
        "outputId": "f6ba15f1-d836-41ca-fdfe-3089a1aed066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9770042194092827\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      2131\n",
            "           1       0.99      0.96      0.98      2609\n",
            "\n",
            "    accuracy                           0.98      4740\n",
            "   macro avg       0.98      0.98      0.98      4740\n",
            "weighted avg       0.98      0.98      0.98      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "D4TNUQlbtWQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VULS1LxtUIJ",
        "outputId": "2a44c6a2-291a-4c36-8bbc-e9cac43ee2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9765822784810126\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1445\n",
            "           1       0.99      0.96      0.98      1715\n",
            "\n",
            "    accuracy                           0.98      3160\n",
            "   macro avg       0.98      0.98      0.98      3160\n",
            "weighted avg       0.98      0.98      0.98      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "jSV6aK90w65P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8V0mVjWyTcr",
        "outputId": "5b6d2362-fd4b-4f53-c625-4dd73b568689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9772151898734177\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       719\n",
            "           1       1.00      0.96      0.98       861\n",
            "\n",
            "    accuracy                           0.98      1580\n",
            "   macro avg       0.98      0.98      0.98      1580\n",
            "weighted avg       0.98      0.98      0.98      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "LqkrcxET3wPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "TLq_Gmvm3zPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and SVC\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ8vEf614Hyf",
        "outputId": "e445bf2b-229d-46ec-9e04-b0be21e108a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9770042194092827\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      2131\n",
            "           1       0.99      0.96      0.98      2609\n",
            "\n",
            "    accuracy                           0.98      4740\n",
            "   macro avg       0.98      0.98      0.98      4740\n",
            "weighted avg       0.98      0.98      0.98      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "_KjOO6cH34OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and SVC\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlCUrne54IOr",
        "outputId": "2a716cb4-29b1-4e67-9924-bf8ecf2c7780"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9765822784810126\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1445\n",
            "           1       0.99      0.96      0.98      1715\n",
            "\n",
            "    accuracy                           0.98      3160\n",
            "   macro avg       0.98      0.98      0.98      3160\n",
            "weighted avg       0.98      0.98      0.98      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "Pj5i1vIT35az"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and SVC\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo-x_htt4Ipn",
        "outputId": "86d4801c-c945-424e-b365-f01a8cd3585e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9772151898734177\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       719\n",
            "           1       1.00      0.96      0.98       861\n",
            "\n",
            "    accuracy                           0.98      1580\n",
            "   macro avg       0.98      0.98      0.98      1580\n",
            "weighted avg       0.98      0.98      0.98      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "qFjWlkdCvN6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [BoW]"
      ],
      "metadata": {
        "id": "V_V5ylyavaoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "q2D15TMUvarj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NB + BoW + 70:30\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert the training data to a single string\n",
        "X_train_text = [\" \".join(tokens) for tokens in X_train]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_text = [\" \".join(tokens) for tokens in X_test]\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Fit the Naive Bayes model on the training data\n",
        "nb_model.fit(X_train_bow, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = nb_model.predict(X_test_bow)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-lAHNeHxazz",
        "outputId": "556d2802-ebef-4045-a57e-86a813876cea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7945147679324894\n",
            "Confusion Matrix:\n",
            "[[1200  931]\n",
            " [  43 2566]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.56      0.71      2131\n",
            "           1       0.73      0.98      0.84      2609\n",
            "\n",
            "    accuracy                           0.79      4740\n",
            "   macro avg       0.85      0.77      0.78      4740\n",
            "weighted avg       0.84      0.79      0.78      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "Mq8-duCwva1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NB + BoW + 80:20\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the training data to a single string\n",
        "X_train_text = [\" \".join(tokens) for tokens in X_train]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_text = [\" \".join(tokens) for tokens in X_test]\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Fit the Naive Bayes model on the training data\n",
        "nb_model.fit(X_train_bow, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = nb_model.predict(X_test_bow)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv_R-h32xcxz",
        "outputId": "ca479a77-3948-4c3e-9b71-399a3e780d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7981012658227848\n",
            "Confusion Matrix:\n",
            "[[ 834  611]\n",
            " [  27 1688]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.58      0.72      1445\n",
            "           1       0.73      0.98      0.84      1715\n",
            "\n",
            "    accuracy                           0.80      3160\n",
            "   macro avg       0.85      0.78      0.78      3160\n",
            "weighted avg       0.84      0.80      0.79      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "HvxlFF-6vbIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#NB + BoW + 80:20\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert the training data to a single string\n",
        "X_train_text = [\" \".join(tokens) for tokens in X_train]\n",
        "\n",
        "# Initialize the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train_text)\n",
        "\n",
        "# Transform the testing data\n",
        "X_test_text = [\" \".join(tokens) for tokens in X_test]\n",
        "X_test_bow = vectorizer.transform(X_test_text)\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Fit the Naive Bayes model on the training data\n",
        "nb_model.fit(X_train_bow, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = nb_model.predict(X_test_bow)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_mat)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw88XQdJxf1F",
        "outputId": "5e387cb9-a33b-40b1-a0c0-f4c19ffe7e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8006329113924051\n",
            "Confusion Matrix:\n",
            "[[416 303]\n",
            " [ 12 849]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.58      0.73       719\n",
            "           1       0.74      0.99      0.84       861\n",
            "\n",
            "    accuracy                           0.80      1580\n",
            "   macro avg       0.85      0.78      0.78      1580\n",
            "weighted avg       0.84      0.80      0.79      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "3sy53eq7vbSr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "uLPGrscwxMtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR + TF-IDF + 70/30\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGNCkbnRxqGy",
        "outputId": "d8b84f6b-afb2-4af9-cbef-b7038d0b5894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7191983122362869\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.40      0.56      2131\n",
            "           1       0.67      0.98      0.79      2609\n",
            "\n",
            "    accuracy                           0.72      4740\n",
            "   macro avg       0.81      0.69      0.68      4740\n",
            "weighted avg       0.79      0.72      0.69      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "qQ9q3CYkxO4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR + TF-IDF + 70/30\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76CZOzIOyBFk",
        "outputId": "38ffcc25-8afa-4440-dbc8-00d7c0edd7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.720253164556962\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.41      0.57      1445\n",
            "           1       0.66      0.98      0.79      1715\n",
            "\n",
            "    accuracy                           0.72      3160\n",
            "   macro avg       0.81      0.70      0.68      3160\n",
            "weighted avg       0.80      0.72      0.69      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "KWvcCIBkxPES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and LogisticRegression\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdpZQu7uyDbs",
        "outputId": "eab659c4-7c8a-4239-d6f3-8979236ed221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7284810126582278\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.42      0.59       719\n",
            "           1       0.67      0.98      0.80       861\n",
            "\n",
            "    accuracy                           0.73      1580\n",
            "   macro avg       0.81      0.70      0.69      1580\n",
            "weighted avg       0.80      0.73      0.70      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "2uASiwhC6Flf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "F714sWh36ILx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXeWwiu66XAF",
        "outputId": "8b09dfc9-9061-418d-a810-684a4c7d7670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7191983122362869\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.40      0.56      2131\n",
            "           1       0.67      0.98      0.79      2609\n",
            "\n",
            "    accuracy                           0.72      4740\n",
            "   macro avg       0.81      0.69      0.68      4740\n",
            "weighted avg       0.79      0.72      0.69      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ---[80/20]---"
      ],
      "metadata": {
        "id": "29MLDOU96Mn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m49kRuQc6Xf4",
        "outputId": "0103d20f-5d57-4762-f8d7-b7dd4ab5416c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.720253164556962\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.41      0.57      1445\n",
            "           1       0.66      0.98      0.79      1715\n",
            "\n",
            "    accuracy                           0.72      3160\n",
            "   macro avg       0.81      0.70      0.68      3160\n",
            "weighted avg       0.80      0.72      0.69      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ---[90/10]---"
      ],
      "metadata": {
        "id": "aJsY5dci6QUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "\n",
        "# Convert X_test to a series of strings\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Create a pipeline that combines TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', TfidfVectorizer()),\n",
        "    ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frq_c-s-6YSw",
        "outputId": "4b52ef44-e732-4c9d-cbec-2c736741add0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7284810126582278\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.42      0.59       719\n",
            "           1       0.67      0.98      0.80       861\n",
            "\n",
            "    accuracy                           0.73      1580\n",
            "   macro avg       0.81      0.70      0.69      1580\n",
            "weighted avg       0.80      0.73      0.70      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning"
      ],
      "metadata": {
        "id": "NAomcYdwiYus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BOW"
      ],
      "metadata": {
        "id": "C7tXhoSbRaGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "g11rb3JxRfU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train to a list of strings\n",
        "X_train = X_train.astype(str).tolist()\n",
        "\n",
        "# Convert X_test to a list of strings\n",
        "X_test = X_test.astype(str).tolist()\n",
        "\n",
        "# Create the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_train_bow = csr_matrix.toarray(X_train_bow)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "X_test_bow = csr_matrix.toarray(X_test_bow)\n",
        "\n",
        "# Create the deep learning model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_dim=X_train_bow.shape[1]),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(X_train_bow, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test_bow, y_test)\n",
        "print(f\"\\nLoss: {loss}, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_bow)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg4MVNlkR0az",
        "outputId": "5421a8fe-4bec-4ad8-c8c4-0d81a42ff051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "312/312 [==============================] - 5s 11ms/step - loss: 0.4169 - accuracy: 0.8489 - val_loss: 0.2274 - val_accuracy: 0.9702\n",
            "Epoch 2/100\n",
            "312/312 [==============================] - 3s 11ms/step - loss: 0.1261 - accuracy: 0.9874 - val_loss: 0.1134 - val_accuracy: 0.9810\n",
            "Epoch 3/100\n",
            "312/312 [==============================] - 3s 8ms/step - loss: 0.0533 - accuracy: 0.9919 - val_loss: 0.0841 - val_accuracy: 0.9792\n",
            "Epoch 4/100\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0306 - accuracy: 0.9950 - val_loss: 0.0744 - val_accuracy: 0.9792\n",
            "Epoch 5/100\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0204 - accuracy: 0.9963 - val_loss: 0.0733 - val_accuracy: 0.9783\n",
            "Epoch 6/100\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0148 - accuracy: 0.9972 - val_loss: 0.0742 - val_accuracy: 0.9774\n",
            "Epoch 7/100\n",
            "312/312 [==============================] - 3s 11ms/step - loss: 0.0113 - accuracy: 0.9978 - val_loss: 0.0767 - val_accuracy: 0.9765\n",
            "149/149 [==============================] - 1s 3ms/step - loss: 0.0837 - accuracy: 0.9774\n",
            "\n",
            "Loss: 0.08373873680830002, Accuracy: 0.9774261713027954\n",
            "\n",
            "149/149 [==============================] - 1s 6ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98      2131\n",
            "           1       0.99      0.97      0.98      2609\n",
            "\n",
            "    accuracy                           0.98      4740\n",
            "   macro avg       0.98      0.98      0.98      4740\n",
            "weighted avg       0.98      0.98      0.98      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "VT9JENdWRjvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train to a list of strings\n",
        "X_train = X_train.astype(str).tolist()\n",
        "\n",
        "# Convert X_test to a list of strings\n",
        "X_test = X_test.astype(str).tolist()\n",
        "\n",
        "# Create the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_train_bow = csr_matrix.toarray(X_train_bow)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "X_test_bow = csr_matrix.toarray(X_test_bow)\n",
        "\n",
        "# Create the deep learning model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_dim=X_train_bow.shape[1]),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(X_train_bow, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test_bow, y_test)\n",
        "print(f\"\\nLoss: {loss}, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_bow)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL_cinPYR05R",
        "outputId": "ab08960b-0512-4456-f300-56351ab1d2e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "356/356 [==============================] - 4s 9ms/step - loss: 0.3802 - accuracy: 0.8948 - val_loss: 0.1785 - val_accuracy: 0.9778\n",
            "Epoch 2/100\n",
            "356/356 [==============================] - 3s 8ms/step - loss: 0.0969 - accuracy: 0.9867 - val_loss: 0.0916 - val_accuracy: 0.9826\n",
            "Epoch 3/100\n",
            "356/356 [==============================] - 4s 11ms/step - loss: 0.0426 - accuracy: 0.9917 - val_loss: 0.0713 - val_accuracy: 0.9826\n",
            "Epoch 4/100\n",
            "356/356 [==============================] - 4s 10ms/step - loss: 0.0255 - accuracy: 0.9947 - val_loss: 0.0637 - val_accuracy: 0.9826\n",
            "Epoch 5/100\n",
            "356/356 [==============================] - 3s 9ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.0603 - val_accuracy: 0.9826\n",
            "Epoch 6/100\n",
            "356/356 [==============================] - 3s 8ms/step - loss: 0.0126 - accuracy: 0.9975 - val_loss: 0.0607 - val_accuracy: 0.9826\n",
            "Epoch 7/100\n",
            "356/356 [==============================] - 3s 10ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 0.0600 - val_accuracy: 0.9818\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9759\n",
            "\n",
            "Loss: 0.08435381948947906, Accuracy: 0.9759493470191956\n",
            "\n",
            "99/99 [==============================] - 0s 4ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1445\n",
            "           1       0.99      0.97      0.98      1715\n",
            "\n",
            "    accuracy                           0.98      3160\n",
            "   macro avg       0.98      0.98      0.98      3160\n",
            "weighted avg       0.98      0.98      0.98      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "L-P3bgG9Rncy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a list of strings\n",
        "X_train = X_train.astype(str).tolist()\n",
        "\n",
        "# Convert X_test to a list of strings\n",
        "X_test = X_test.astype(str).tolist()\n",
        "\n",
        "# Create the CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_train_bow = csr_matrix.toarray(X_train_bow)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_bow = vectorizer.transform(X_test)\n",
        "X_test_bow = csr_matrix.toarray(X_test_bow)\n",
        "\n",
        "# Create the deep learning model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_dim=X_train_bow.shape[1]),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(X_train_bow, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test_bow, y_test)\n",
        "print(f\"\\nLoss: {loss}, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_bow)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPYG3YrgR1S8",
        "outputId": "0562b4a7-e824-4914-e971-7d6e2ad4056a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "400/400 [==============================] - 5s 9ms/step - loss: 0.3570 - accuracy: 0.8883 - val_loss: 0.1555 - val_accuracy: 0.9817\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 6s 15ms/step - loss: 0.0839 - accuracy: 0.9869 - val_loss: 0.0832 - val_accuracy: 0.9824\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.0368 - accuracy: 0.9927 - val_loss: 0.0690 - val_accuracy: 0.9831\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.0222 - accuracy: 0.9955 - val_loss: 0.0644 - val_accuracy: 0.9845\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 5s 13ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 0.0636 - val_accuracy: 0.9852\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.0657 - val_accuracy: 0.9838\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 4s 11ms/step - loss: 0.0086 - accuracy: 0.9986 - val_loss: 0.0669 - val_accuracy: 0.9838\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 5s 13ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0696 - val_accuracy: 0.9831\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 4s 11ms/step - loss: 0.0056 - accuracy: 0.9989 - val_loss: 0.0728 - val_accuracy: 0.9817\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 5s 12ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0766 - val_accuracy: 0.9817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7d8189423d00>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 103, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 5ms/step - loss: 0.0977 - accuracy: 0.9747\n",
            "\n",
            "Loss: 0.09774645417928696, Accuracy: 0.9746835231781006\n",
            "\n",
            "50/50 [==============================] - 0s 6ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97       719\n",
            "           1       0.99      0.97      0.98       861\n",
            "\n",
            "    accuracy                           0.97      1580\n",
            "   macro avg       0.97      0.98      0.97      1580\n",
            "weighted avg       0.97      0.97      0.97      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TFIDF"
      ],
      "metadata": {
        "id": "p5r7_OwrvWuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "wpY-hMR-EXJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train to a list of strings\n",
        "X_train = X_train.astype(str).tolist()\n",
        "\n",
        "# Convert X_test to a list of strings\n",
        "X_test = X_test.astype(str).tolist()\n",
        "\n",
        "# Create the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_train_tfidf = csr_matrix.toarray(X_train_tfidf)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "X_test_tfidf = csr_matrix.toarray(X_test_tfidf)\n",
        "\n",
        "# Create the deep learning model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_dim=X_train_tfidf.shape[1]),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(X_train_tfidf, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
        "print(f\"\\nLoss: {loss}, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_tfidf)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "5xRqbeuKyE2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1489d739-fcad-473e-e0c4-3fb299b55737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.5685 - accuracy: 0.8022 - val_loss: 0.4319 - val_accuracy: 0.9195\n",
            "Epoch 2/100\n",
            "312/312 [==============================] - 2s 8ms/step - loss: 0.2952 - accuracy: 0.9537 - val_loss: 0.2784 - val_accuracy: 0.9277\n",
            "Epoch 3/100\n",
            "312/312 [==============================] - 4s 12ms/step - loss: 0.1538 - accuracy: 0.9800 - val_loss: 0.2102 - val_accuracy: 0.9403\n",
            "Epoch 4/100\n",
            "312/312 [==============================] - 3s 11ms/step - loss: 0.0882 - accuracy: 0.9906 - val_loss: 0.1761 - val_accuracy: 0.9521\n",
            "Epoch 5/100\n",
            "312/312 [==============================] - 3s 10ms/step - loss: 0.0553 - accuracy: 0.9945 - val_loss: 0.1580 - val_accuracy: 0.9512\n",
            "Epoch 6/100\n",
            "312/312 [==============================] - 3s 10ms/step - loss: 0.0372 - accuracy: 0.9963 - val_loss: 0.1474 - val_accuracy: 0.9503\n",
            "Epoch 7/100\n",
            "312/312 [==============================] - 3s 10ms/step - loss: 0.0264 - accuracy: 0.9975 - val_loss: 0.1414 - val_accuracy: 0.9512\n",
            "Epoch 8/100\n",
            "312/312 [==============================] - 3s 8ms/step - loss: 0.0195 - accuracy: 0.9980 - val_loss: 0.1378 - val_accuracy: 0.9530\n",
            "Epoch 9/100\n",
            "312/312 [==============================] - 3s 8ms/step - loss: 0.0149 - accuracy: 0.9989 - val_loss: 0.1380 - val_accuracy: 0.9521\n",
            "Epoch 10/100\n",
            "312/312 [==============================] - 3s 8ms/step - loss: 0.0117 - accuracy: 0.9991 - val_loss: 0.1373 - val_accuracy: 0.9539\n",
            "Epoch 11/100\n",
            "312/312 [==============================] - 3s 10ms/step - loss: 0.0094 - accuracy: 0.9993 - val_loss: 0.1374 - val_accuracy: 0.9521\n",
            "Epoch 12/100\n",
            "312/312 [==============================] - 3s 9ms/step - loss: 0.0077 - accuracy: 0.9995 - val_loss: 0.1389 - val_accuracy: 0.9512\n",
            "Epoch 13/100\n",
            "312/312 [==============================] - 2s 8ms/step - loss: 0.0064 - accuracy: 0.9997 - val_loss: 0.1391 - val_accuracy: 0.9503\n",
            "Epoch 14/100\n",
            "312/312 [==============================] - 2s 8ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 0.1413 - val_accuracy: 0.9512\n",
            "Epoch 15/100\n",
            "312/312 [==============================] - 2s 8ms/step - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.1422 - val_accuracy: 0.9503\n",
            "149/149 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9441\n",
            "\n",
            "Loss: 0.15738356113433838, Accuracy: 0.9440928101539612\n",
            "\n",
            "149/149 [==============================] - 1s 3ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.94      0.94      2131\n",
            "           1       0.95      0.94      0.95      2609\n",
            "\n",
            "    accuracy                           0.94      4740\n",
            "   macro avg       0.94      0.94      0.94      4740\n",
            "weighted avg       0.94      0.94      0.94      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "ZziFKJgdEhtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train to a list of strings\n",
        "X_train = X_train.astype(str).tolist()\n",
        "\n",
        "# Convert X_test to a list of strings\n",
        "X_test = X_test.astype(str).tolist()\n",
        "\n",
        "# Create the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_train_tfidf = csr_matrix.toarray(X_train_tfidf)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "X_test_tfidf = csr_matrix.toarray(X_test_tfidf)\n",
        "\n",
        "# Create the deep learning model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_dim=X_train_tfidf.shape[1]),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(X_train_tfidf, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
        "print(f\"\\nLoss: {loss}, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_tfidf)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_tfidf_2 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SM6KuJJEsk1",
        "outputId": "8e345327-4b68-4677-8bf9-37a2bc098a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "356/356 [==============================] - 4s 9ms/step - loss: 0.5679 - accuracy: 0.8431 - val_loss: 0.4204 - val_accuracy: 0.9130\n",
            "Epoch 2/100\n",
            "356/356 [==============================] - 3s 8ms/step - loss: 0.2798 - accuracy: 0.9568 - val_loss: 0.2575 - val_accuracy: 0.9272\n",
            "Epoch 3/100\n",
            "356/356 [==============================] - 4s 11ms/step - loss: 0.1384 - accuracy: 0.9817 - val_loss: 0.1877 - val_accuracy: 0.9509\n",
            "Epoch 4/100\n",
            "356/356 [==============================] - 3s 9ms/step - loss: 0.0779 - accuracy: 0.9911 - val_loss: 0.1557 - val_accuracy: 0.9541\n",
            "Epoch 5/100\n",
            "356/356 [==============================] - 3s 8ms/step - loss: 0.0486 - accuracy: 0.9939 - val_loss: 0.1388 - val_accuracy: 0.9549\n",
            "Epoch 6/100\n",
            "356/356 [==============================] - 3s 8ms/step - loss: 0.0329 - accuracy: 0.9960 - val_loss: 0.1290 - val_accuracy: 0.9573\n",
            "Epoch 7/100\n",
            "356/356 [==============================] - 4s 10ms/step - loss: 0.0235 - accuracy: 0.9977 - val_loss: 0.1239 - val_accuracy: 0.9549\n",
            "Epoch 8/100\n",
            "356/356 [==============================] - 3s 9ms/step - loss: 0.0174 - accuracy: 0.9982 - val_loss: 0.1198 - val_accuracy: 0.9549\n",
            "Epoch 9/100\n",
            "356/356 [==============================] - 3s 8ms/step - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.1189 - val_accuracy: 0.9557\n",
            "Epoch 10/100\n",
            "356/356 [==============================] - 3s 8ms/step - loss: 0.0106 - accuracy: 0.9989 - val_loss: 0.1185 - val_accuracy: 0.9565\n",
            "Epoch 11/100\n",
            "356/356 [==============================] - 4s 10ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.1192 - val_accuracy: 0.9565\n",
            "99/99 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9513\n",
            "\n",
            "Loss: 0.13793937861919403, Accuracy: 0.951265811920166\n",
            "\n",
            "99/99 [==============================] - 0s 3ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95      1445\n",
            "           1       0.96      0.94      0.95      1715\n",
            "\n",
            "    accuracy                           0.95      3160\n",
            "   macro avg       0.95      0.95      0.95      3160\n",
            "weighted avg       0.95      0.95      0.95      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "JWkX-HCZEmn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "from scipy.sparse import csr_matrix\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a list of strings\n",
        "X_train = X_train.astype(str).tolist()\n",
        "\n",
        "# Convert X_test to a list of strings\n",
        "X_test = X_test.astype(str).tolist()\n",
        "\n",
        "# Create the TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit the vectorizer on the training data\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_train_tfidf = csr_matrix.toarray(X_train_tfidf)\n",
        "\n",
        "# Transform the test data using the fitted vectorizer\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "X_test_tfidf = csr_matrix.toarray(X_test_tfidf)\n",
        "\n",
        "# Create the deep learning model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(16, activation='relu', input_dim=X_train_tfidf.shape[1]),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping criteria\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(X_train_tfidf, y_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(X_test_tfidf, y_test)\n",
        "print(f\"\\nLoss: {loss}, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test_tfidf)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "LR_tfidf_3 = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trWf_09nEtIB",
        "outputId": "1f8a6c80-f51a-4568-b914-bef3fc980057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "400/400 [==============================] - 5s 11ms/step - loss: 0.5340 - accuracy: 0.8093 - val_loss: 0.3727 - val_accuracy: 0.9170\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - 3s 8ms/step - loss: 0.2432 - accuracy: 0.9602 - val_loss: 0.2253 - val_accuracy: 0.9451\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - 3s 8ms/step - loss: 0.1189 - accuracy: 0.9838 - val_loss: 0.1671 - val_accuracy: 0.9578\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - 4s 11ms/step - loss: 0.0667 - accuracy: 0.9916 - val_loss: 0.1399 - val_accuracy: 0.9599\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - 3s 8ms/step - loss: 0.0418 - accuracy: 0.9946 - val_loss: 0.1269 - val_accuracy: 0.9606\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - 3s 8ms/step - loss: 0.0282 - accuracy: 0.9969 - val_loss: 0.1201 - val_accuracy: 0.9620\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - 4s 10ms/step - loss: 0.0200 - accuracy: 0.9975 - val_loss: 0.1159 - val_accuracy: 0.9613\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - 3s 8ms/step - loss: 0.0148 - accuracy: 0.9979 - val_loss: 0.1143 - val_accuracy: 0.9613\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - 3s 6ms/step - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.1161 - val_accuracy: 0.9585\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - 2s 6ms/step - loss: 0.0089 - accuracy: 0.9991 - val_loss: 0.1164 - val_accuracy: 0.9592\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - 3s 6ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.1157 - val_accuracy: 0.9599\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9551\n",
            "\n",
            "Loss: 0.13483615219593048, Accuracy: 0.9550632834434509\n",
            "\n",
            "50/50 [==============================] - 0s 2ms/step\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95       719\n",
            "           1       0.97      0.95      0.96       861\n",
            "\n",
            "    accuracy                           0.96      1580\n",
            "   macro avg       0.95      0.96      0.95      1580\n",
            "weighted avg       0.96      0.96      0.96      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word2Vec"
      ],
      "metadata": {
        "id": "0YAFKQyvvcQF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [70/30] ---"
      ],
      "metadata": {
        "id": "EP_xwYtrTT1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Assuming you have a dataset with 'cleaned_tweet' as input and 'label' as the corresponding sentiment labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.3, random_state=42)\n",
        "\n",
        "# Convert X_train and X_test to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_texts_train = [text.split() for text in X_train]\n",
        "tokenized_texts_test = [text.split() for text in X_test]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(tokenized_texts_train, min_count=1)\n",
        "\n",
        "def convert_to_embeddings(text):\n",
        "    embeddings = [model.wv[word] for word in text if word in model.wv]\n",
        "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(model.vector_size)\n",
        "\n",
        "# Convert the tokenized texts to Word2Vec embeddings\n",
        "X_train_embeddings = np.array([convert_to_embeddings(text) for text in tokenized_texts_train])\n",
        "X_test_embeddings = np.array([convert_to_embeddings(text) for text in tokenized_texts_test])\n",
        "\n",
        "# Get the size of Word2Vec embeddings\n",
        "embedding_size = model.vector_size\n",
        "\n",
        "# Define the deep neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(embedding_size,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_embeddings, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred_prob = model.predict(X_test_embeddings)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__dHrznnTjgr",
        "outputId": "7f20180b-ae9a-4bad-979b-b5cd27674456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.4827 - accuracy: 0.7531\n",
            "Epoch 2/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.4171 - accuracy: 0.7986\n",
            "Epoch 3/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.4119 - accuracy: 0.8033\n",
            "Epoch 4/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8011\n",
            "Epoch 5/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.4055 - accuracy: 0.8042\n",
            "Epoch 6/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.4054 - accuracy: 0.8039\n",
            "Epoch 7/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.4026 - accuracy: 0.8053\n",
            "Epoch 8/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.3991 - accuracy: 0.8090\n",
            "Epoch 9/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.3970 - accuracy: 0.8106\n",
            "Epoch 10/10\n",
            "346/346 [==============================] - 1s 2ms/step - loss: 0.3953 - accuracy: 0.8146\n",
            "149/149 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.8046413502109705\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.79      0.78      2131\n",
            "           1       0.83      0.81      0.82      2609\n",
            "\n",
            "    accuracy                           0.80      4740\n",
            "   macro avg       0.80      0.80      0.80      4740\n",
            "weighted avg       0.81      0.80      0.80      4740\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [80/20] ---"
      ],
      "metadata": {
        "id": "snAIUye0TTpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Assuming you have a dataset with 'cleaned_tweet' as input and 'label' as the corresponding sentiment labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert X_train and X_test to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_texts_train = [text.split() for text in X_train]\n",
        "tokenized_texts_test = [text.split() for text in X_test]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(tokenized_texts_train, min_count=1)\n",
        "\n",
        "def convert_to_embeddings(text):\n",
        "    embeddings = [model.wv[word] for word in text if word in model.wv]\n",
        "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(model.vector_size)\n",
        "\n",
        "# Convert the tokenized texts to Word2Vec embeddings\n",
        "X_train_embeddings = np.array([convert_to_embeddings(text) for text in tokenized_texts_train])\n",
        "X_test_embeddings = np.array([convert_to_embeddings(text) for text in tokenized_texts_test])\n",
        "\n",
        "# Get the size of Word2Vec embeddings\n",
        "embedding_size = model.vector_size\n",
        "\n",
        "# Define the deep neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(embedding_size,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_embeddings, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred_prob = model.predict(X_test_embeddings)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "MZx1sO0_TkAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4adedc5d-9447-4519-a7e5-2e6df817fe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.4838 - accuracy: 0.7516\n",
            "Epoch 2/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.4120 - accuracy: 0.8009\n",
            "Epoch 3/10\n",
            "395/395 [==============================] - 1s 2ms/step - loss: 0.4049 - accuracy: 0.8057\n",
            "Epoch 4/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.3988 - accuracy: 0.8095\n",
            "Epoch 5/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.3944 - accuracy: 0.8106\n",
            "Epoch 6/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.3894 - accuracy: 0.8177\n",
            "Epoch 7/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.3868 - accuracy: 0.8218\n",
            "Epoch 8/10\n",
            "395/395 [==============================] - 1s 2ms/step - loss: 0.3859 - accuracy: 0.8172\n",
            "Epoch 9/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.3817 - accuracy: 0.8232\n",
            "Epoch 10/10\n",
            "395/395 [==============================] - 1s 1ms/step - loss: 0.3810 - accuracy: 0.8218\n",
            "99/99 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.8177215189873418\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.76      0.79      1445\n",
            "           1       0.81      0.86      0.84      1715\n",
            "\n",
            "    accuracy                           0.82      3160\n",
            "   macro avg       0.82      0.81      0.82      3160\n",
            "weighted avg       0.82      0.82      0.82      3160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### --- [90/10] ---"
      ],
      "metadata": {
        "id": "Ms209dR3TTUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from gensim.models import Word2Vec\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Assuming you have a dataset with 'cleaned_tweet' as input and 'label' as the corresponding sentiment labels\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train and X_test to a series of strings\n",
        "X_train = X_train.astype(str)\n",
        "X_test = X_test.astype(str)\n",
        "\n",
        "# Tokenize the text\n",
        "tokenized_texts_train = [text.split() for text in X_train]\n",
        "tokenized_texts_test = [text.split() for text in X_test]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(tokenized_texts_train, min_count=1)\n",
        "\n",
        "def convert_to_embeddings(text):\n",
        "    embeddings = [model.wv[word] for word in text if word in model.wv]\n",
        "    return np.mean(embeddings, axis=0) if embeddings else np.zeros(model.vector_size)\n",
        "\n",
        "# Convert the tokenized texts to Word2Vec embeddings\n",
        "X_train_embeddings = np.array([convert_to_embeddings(text) for text in tokenized_texts_train])\n",
        "X_test_embeddings = np.array([convert_to_embeddings(text) for text in tokenized_texts_test])\n",
        "\n",
        "# Get the size of Word2Vec embeddings\n",
        "embedding_size = model.vector_size\n",
        "\n",
        "# Define the deep neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(embedding_size,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_embeddings, y_train, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred_prob = model.predict(X_test_embeddings)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "vNQoibaLTkmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8effbe76-d5f0-4b8f-bf6a-460e302a3f1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "445/445 [==============================] - 2s 2ms/step - loss: 0.4636 - accuracy: 0.7672\n",
            "Epoch 2/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.4126 - accuracy: 0.8024\n",
            "Epoch 3/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.4051 - accuracy: 0.8014\n",
            "Epoch 4/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.3971 - accuracy: 0.8085\n",
            "Epoch 5/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.3931 - accuracy: 0.8082\n",
            "Epoch 6/10\n",
            "445/445 [==============================] - 1s 1ms/step - loss: 0.3900 - accuracy: 0.8116\n",
            "Epoch 7/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.3867 - accuracy: 0.8148\n",
            "Epoch 8/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.3827 - accuracy: 0.8177\n",
            "Epoch 9/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.3795 - accuracy: 0.8175\n",
            "Epoch 10/10\n",
            "445/445 [==============================] - 1s 2ms/step - loss: 0.3781 - accuracy: 0.8203\n",
            "50/50 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.8132911392405063\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.76      0.79       719\n",
            "           1       0.81      0.85      0.83       861\n",
            "\n",
            "    accuracy                           0.81      1580\n",
            "   macro avg       0.81      0.81      0.81      1580\n",
            "weighted avg       0.81      0.81      0.81      1580\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['label'], test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert X_train to a list of strings\n",
        "X_train = X_train.tolist()\n",
        "\n",
        "# Convert X_test to a list of strings\n",
        "X_test = X_test.tolist()\n",
        "\n",
        "# Train Word2Vec embeddings on the text data\n",
        "embedding_dim = 100\n",
        "model = Word2Vec(sentences=X_train, vector_size=embedding_dim, window=5, min_count=1)\n",
        "\n",
        "# Tokenize the text and convert it to sequences\n",
        "tokenizer = keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "sequences_train = tokenizer.texts_to_sequences(X_train)\n",
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "max_sequence_length = max(max(len(seq) for seq in sequences_train), max(len(seq) for seq in sequences_test))\n",
        "padded_sequences_train = keras.preprocessing.sequence.pad_sequences(sequences_train, maxlen=max_sequence_length)\n",
        "padded_sequences_test = keras.preprocessing.sequence.pad_sequences(sequences_test, maxlen=max_sequence_length)\n",
        "\n",
        "# Create the deep learning model with Word2Vec embeddings\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in model.wv:\n",
        "        embedding_matrix[i] = model.wv[word]\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length,\n",
        "                           weights=[embedding_matrix], trainable=False),\n",
        "    keras.layers.LSTM(64),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(padded_sequences_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model.evaluate(padded_sequences_test, y_test)\n",
        "print(f\"\\nLoss: {loss}, Accuracy: {accuracy}\\n\")\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(padded_sequences_test)\n",
        "predicted_labels = [1 if pred > 0.5 else 0 for pred in predictions]\n",
        "\n",
        "# Generate a classification report\n",
        "report = classification_report(y_test, predicted_labels)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "TVJt4c0Xi2To",
        "outputId": "124883a1-b32f-4f39-b1a9-73cf3f9bd091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "351/445 [======================>.......] - ETA: 15s - loss: 0.3918 - accuracy: 0.8178"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-59a37e0105ad>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_sequences_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Evaluate the model on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exporting"
      ],
      "metadata": {
        "id": "W7QfyHf2vleZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create an empty DataFrame\n",
        "LR = pd.DataFrame(columns=['LR Experiment', 'Value'])"
      ],
      "metadata": {
        "id": "599J1Nsuvnms"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exp = ['BoW + 70/30', 'BoW + 80/20', 'BoW + 90/10','TF-IDF + 70/30', 'TF-IDF + 80/20', 'TF-IDF + 90/10','Word2Vec + 70/30','Word2Vec + 80/20','Word2Vec + 90/10']"
      ],
      "metadata": {
        "id": "DgigtLwzyd4T"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "values = [LR_bow_1, LR_bow_2,LR_bow_3,LR_tfidf_1,LR_tfidf_2,LR_tfidf_3,LR_word2vec_1,LR_word2vec_2,LR_word2vec_3]"
      ],
      "metadata": {
        "id": "GoOxN2LVzEnx"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(exp)):\n",
        "    LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he4DhElg9-G0",
        "outputId": "a58fe691-a060-4253-e55a-f87ad15ce57b"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n",
            "<ipython-input-79-de7bee71b595>:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  LR = LR.append({'LR Experiment': exp[i], 'Value': values[i]}, ignore_index=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "FY5Q9gsLx6ah",
        "outputId": "73c72875-f197-4e4a-884d-af75a40ce826"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      LR Experiment     Value\n",
              "0       BoW + 70/30  0.982489\n",
              "1       BoW + 80/20  0.981962\n",
              "2       BoW + 90/10  0.983544\n",
              "3    TF-IDF + 70/30  0.973418\n",
              "4    TF-IDF + 80/20  0.951266\n",
              "5    TF-IDF + 90/10  0.955063\n",
              "6  Word2Vec + 70/30  0.772574\n",
              "7  Word2Vec + 80/20  0.773418\n",
              "8  Word2Vec + 90/10  0.767089"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-61221b90-1b46-4e69-bc15-730c1778e0a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LR Experiment</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BoW + 70/30</td>\n",
              "      <td>0.982489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BoW + 80/20</td>\n",
              "      <td>0.981962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BoW + 90/10</td>\n",
              "      <td>0.983544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TF-IDF + 70/30</td>\n",
              "      <td>0.973418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TF-IDF + 80/20</td>\n",
              "      <td>0.951266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TF-IDF + 90/10</td>\n",
              "      <td>0.955063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Word2Vec + 70/30</td>\n",
              "      <td>0.772574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Word2Vec + 80/20</td>\n",
              "      <td>0.773418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Word2Vec + 90/10</td>\n",
              "      <td>0.767089</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61221b90-1b46-4e69-bc15-730c1778e0a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-d936b09d-510a-4b1d-8e0f-2bb5dbdbd7aa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d936b09d-510a-4b1d-8e0f-2bb5dbdbd7aa')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-d936b09d-510a-4b1d-8e0f-2bb5dbdbd7aa button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61221b90-1b46-4e69-bc15-730c1778e0a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61221b90-1b46-4e69-bc15-730c1778e0a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the output file path\n",
        "output_file = 'LR.xlsx'\n",
        "\n",
        "# Write the DataFrame to Excel\n",
        "LR.to_excel(output_file, index=False)\n",
        "\n",
        "print(\"Data has been written to\", output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DsTWjb_-R61",
        "outputId": "ad9bce08-d229-4fca-9053-88495dda0e26"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been written to LR.xlsx\n"
          ]
        }
      ]
    }
  ]
}